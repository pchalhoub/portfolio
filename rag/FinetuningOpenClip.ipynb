{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgvzHZ0IM5G9",
        "outputId": "6a1ced5b-dd9c-498d-c3b6-e19de778e105"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'open_clip'...\n",
            "remote: Enumerating objects: 3644, done.\u001b[K\n",
            "remote: Counting objects: 100% (104/104), done.\u001b[K\n",
            "remote: Compressing objects: 100% (54/54), done.\u001b[K\n",
            "remote: Total 3644 (delta 68), reused 57 (delta 50), pack-reused 3540 (from 3)\u001b[K\n",
            "Receiving objects: 100% (3644/3644), 15.42 MiB | 29.30 MiB/s, done.\n",
            "Resolving deltas: 100% (2201/2201), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/mlfoundations/open_clip.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install torch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 --index-url https://download.pytorch.org/whl/cu117"
      ],
      "metadata": {
        "id": "tll6HagEN5v6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install open_clip_torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4W-P_25OOuu",
        "outputId": "2fe901b2-aebc-456b-ff07-bce278e19877"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting open_clip_torch\n",
            "  Downloading open_clip_torch-2.32.0-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (2.0.1+cu117)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (0.15.2+cu117)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (2024.11.6)\n",
            "Collecting ftfy (from open_clip_torch)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (4.67.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (0.30.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (0.5.3)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (1.0.15)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (4.13.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (3.1.6)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch>=1.9.0->open_clip_torch) (3.31.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch>=1.9.0->open_clip_torch) (15.0.7)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->open_clip_torch) (0.2.13)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->open_clip_torch) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->open_clip_torch) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->open_clip_torch) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->open_clip_torch) (2.32.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->open_clip_torch) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->open_clip_torch) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9.0->open_clip_torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open_clip_torch) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open_clip_torch) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open_clip_torch) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open_clip_torch) (2025.1.31)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.9.0->open_clip_torch) (1.3.0)\n",
            "Downloading open_clip_torch-2.32.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ftfy, open_clip_torch\n",
            "Successfully installed ftfy-6.3.1 open_clip_torch-2.32.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCHVRgTJORrg",
        "outputId": "9fc99807-4866-405a-96c5-eee8040e20b5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%ls"
      ],
      "metadata": {
        "id": "VU9duOALOgay"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install braceexpand"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQTRz_P8OhaC",
        "outputId": "344357d3-6002-49c4-9413-061138e2d93b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting braceexpand\n",
            "  Downloading braceexpand-0.1.7-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Downloading braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
            "Installing collected packages: braceexpand\n",
            "Successfully installed braceexpand-0.1.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install webdataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ss6jJpscOlW5",
        "outputId": "880bd768-ccc3-4b01-b1a9-109bb4f71ac3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting webdataset\n",
            "  Downloading webdataset-0.2.111-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: braceexpand in /usr/local/lib/python3.11/dist-packages (from webdataset) (0.1.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from webdataset) (2.0.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from webdataset) (6.0.2)\n",
            "Downloading webdataset-0.2.111-py3-none-any.whl (85 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/85.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: webdataset\n",
            "Successfully installed webdataset-0.2.111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y thinc spacy\n",
        "!pip install \"numpy<2.0\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqDaqfb6OoKm",
        "outputId": "9a2826fc-e946-46b9-bf84-6f27c2ac631b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: thinc 8.3.6\n",
            "Uninstalling thinc-8.3.6:\n",
            "  Successfully uninstalled thinc-8.3.6\n",
            "Found existing installation: spacy 3.8.5\n",
            "Uninstalling spacy-3.8.5:\n",
            "  Successfully uninstalled spacy-3.8.5\n",
            "Collecting numpy<2.0\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m98.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.19 requires spacy<4, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m open_clip_train.main \\\n",
        "    --train-data=\"11trainingdata.csv\" \\\n",
        "    --save-frequency 1 \\\n",
        "    --zeroshot-frequency 1 \\\n",
        "    --report-to tensorboard \\\n",
        "    --csv-separator ',' \\\n",
        "    --csv-img-key image_path \\\n",
        "    --csv-caption-key caption \\\n",
        "    --warmup 10000 \\\n",
        "    --batch-size=128 \\\n",
        "    --lr=1e-3 \\\n",
        "    --wd=0.1 \\\n",
        "    --epochs=30 \\\n",
        "    --workers=8 \\\n",
        "    --model ViT-B-32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qvBPKKvOrg6",
        "outputId": "1f984ffa-ea06-4979-c6f4-0e93ad70f1cb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-19 01:43:14.495814: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1745026994.517572    6403 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1745026994.524535    6403 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-19 01:43:14.546929: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-04-19,01:43:19 | INFO | Running with a single process. Device cuda.\n",
            "2025-04-19,01:43:19 | INFO | Loaded ViT-B-32 model config.\n",
            "2025-04-19,01:43:23 | INFO | Model:\n",
            "2025-04-19,01:43:23 | INFO | CLIP(\n",
            "  (visual): VisionTransformer(\n",
            "    (conv1): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
            "    (patch_dropout): Identity()\n",
            "    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    (transformer): Transformer(\n",
            "      (resblocks): ModuleList(\n",
            "        (0-11): 12 x ResidualAttentionBlock(\n",
            "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (ls_1): Identity()\n",
            "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Sequential(\n",
            "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (gelu): GELU(approximate='none')\n",
            "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          )\n",
            "          (ls_2): Identity()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (transformer): Transformer(\n",
            "    (resblocks): ModuleList(\n",
            "      (0-11): 12 x ResidualAttentionBlock(\n",
            "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (ls_1): Identity()\n",
            "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Sequential(\n",
            "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (gelu): GELU(approximate='none')\n",
            "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        )\n",
            "        (ls_2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (token_embedding): Embedding(49408, 512)\n",
            "  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            ")\n",
            "2025-04-19,01:43:23 | INFO | Params:\n",
            "2025-04-19,01:43:23 | INFO |   accum_freq: 1\n",
            "2025-04-19,01:43:23 | INFO |   aug_cfg: {}\n",
            "2025-04-19,01:43:23 | INFO |   batch_size: 128\n",
            "2025-04-19,01:43:23 | INFO |   beta1: 0.9\n",
            "2025-04-19,01:43:23 | INFO |   beta2: 0.98\n",
            "2025-04-19,01:43:23 | INFO |   cache_dir: None\n",
            "2025-04-19,01:43:23 | INFO |   checkpoint_path: ./logs/2025_04_19-01_43_19-model_ViT-B-32-lr_0.001-b_128-j_8-p_amp/checkpoints\n",
            "2025-04-19,01:43:23 | INFO |   coca_caption_loss_weight: 2.0\n",
            "2025-04-19,01:43:23 | INFO |   coca_contrastive_loss_weight: 1.0\n",
            "2025-04-19,01:43:23 | INFO |   copy_codebase: False\n",
            "2025-04-19,01:43:23 | INFO |   csv_caption_key: topic\n",
            "2025-04-19,01:43:23 | INFO |   csv_img_key: image_path\n",
            "2025-04-19,01:43:23 | INFO |   csv_separator: ,\n",
            "2025-04-19,01:43:23 | INFO |   dataset_resampled: False\n",
            "2025-04-19,01:43:23 | INFO |   dataset_type: auto\n",
            "2025-04-19,01:43:23 | INFO |   ddp_static_graph: False\n",
            "2025-04-19,01:43:23 | INFO |   debug: False\n",
            "2025-04-19,01:43:23 | INFO |   delete_previous_checkpoint: False\n",
            "2025-04-19,01:43:23 | INFO |   device: cuda\n",
            "2025-04-19,01:43:23 | INFO |   dist_backend: None\n",
            "2025-04-19,01:43:23 | INFO |   dist_url: None\n",
            "2025-04-19,01:43:23 | INFO |   distill: False\n",
            "2025-04-19,01:43:23 | INFO |   distill_model: None\n",
            "2025-04-19,01:43:23 | INFO |   distill_pretrained: None\n",
            "2025-04-19,01:43:23 | INFO |   distributed: False\n",
            "2025-04-19,01:43:23 | INFO |   epochs: 30\n",
            "2025-04-19,01:43:23 | INFO |   epochs_cooldown: None\n",
            "2025-04-19,01:43:23 | INFO |   eps: 1e-06\n",
            "2025-04-19,01:43:23 | INFO |   force_custom_text: False\n",
            "2025-04-19,01:43:23 | INFO |   force_image_size: None\n",
            "2025-04-19,01:43:23 | INFO |   force_patch_dropout: None\n",
            "2025-04-19,01:43:23 | INFO |   force_quick_gelu: False\n",
            "2025-04-19,01:43:23 | INFO |   gather_with_grad: False\n",
            "2025-04-19,01:43:23 | INFO |   grad_checkpointing: False\n",
            "2025-04-19,01:43:23 | INFO |   grad_clip_norm: None\n",
            "2025-04-19,01:43:23 | INFO |   horovod: False\n",
            "2025-04-19,01:43:23 | INFO |   image_interpolation: None\n",
            "2025-04-19,01:43:23 | INFO |   image_mean: None\n",
            "2025-04-19,01:43:23 | INFO |   image_resize_mode: None\n",
            "2025-04-19,01:43:23 | INFO |   image_std: None\n",
            "2025-04-19,01:43:23 | INFO |   imagenet_v2: None\n",
            "2025-04-19,01:43:23 | INFO |   imagenet_val: None\n",
            "2025-04-19,01:43:23 | INFO |   local_loss: False\n",
            "2025-04-19,01:43:23 | INFO |   local_rank: 0\n",
            "2025-04-19,01:43:23 | INFO |   lock_image: False\n",
            "2025-04-19,01:43:23 | INFO |   lock_image_freeze_bn_stats: False\n",
            "2025-04-19,01:43:23 | INFO |   lock_image_unlocked_groups: 0\n",
            "2025-04-19,01:43:23 | INFO |   lock_text: False\n",
            "2025-04-19,01:43:23 | INFO |   lock_text_freeze_layer_norm: False\n",
            "2025-04-19,01:43:23 | INFO |   lock_text_unlocked_layers: 0\n",
            "2025-04-19,01:43:23 | INFO |   log_every_n_steps: 100\n",
            "2025-04-19,01:43:23 | INFO |   log_level: 20\n",
            "2025-04-19,01:43:23 | INFO |   log_local: False\n",
            "2025-04-19,01:43:23 | INFO |   log_path: ./logs/2025_04_19-01_43_19-model_ViT-B-32-lr_0.001-b_128-j_8-p_amp/out.log\n",
            "2025-04-19,01:43:23 | INFO |   logs: ./logs/\n",
            "2025-04-19,01:43:23 | INFO |   loss_dist_impl: None\n",
            "2025-04-19,01:43:23 | INFO |   lr: 0.001\n",
            "2025-04-19,01:43:23 | INFO |   lr_cooldown_end: 0.0\n",
            "2025-04-19,01:43:23 | INFO |   lr_cooldown_power: 1.0\n",
            "2025-04-19,01:43:23 | INFO |   lr_scheduler: cosine\n",
            "2025-04-19,01:43:23 | INFO |   model: ViT-B-32\n",
            "2025-04-19,01:43:23 | INFO |   momentum: None\n",
            "2025-04-19,01:43:23 | INFO |   name: 2025_04_19-01_43_19-model_ViT-B-32-lr_0.001-b_128-j_8-p_amp\n",
            "2025-04-19,01:43:23 | INFO |   no_set_device_rank: False\n",
            "2025-04-19,01:43:23 | INFO |   opt: adamw\n",
            "2025-04-19,01:43:23 | INFO |   precision: amp\n",
            "2025-04-19,01:43:23 | INFO |   pretrained: \n",
            "2025-04-19,01:43:23 | INFO |   pretrained_image: False\n",
            "2025-04-19,01:43:23 | INFO |   rank: 0\n",
            "2025-04-19,01:43:23 | INFO |   remote_sync: None\n",
            "2025-04-19,01:43:23 | INFO |   remote_sync_frequency: 300\n",
            "2025-04-19,01:43:23 | INFO |   remote_sync_protocol: s3\n",
            "2025-04-19,01:43:23 | INFO |   report_to: tensorboard\n",
            "2025-04-19,01:43:23 | INFO |   resume: None\n",
            "2025-04-19,01:43:23 | INFO |   save_frequency: 1\n",
            "2025-04-19,01:43:23 | INFO |   save_most_recent: False\n",
            "2025-04-19,01:43:23 | INFO |   seed: 0\n",
            "2025-04-19,01:43:23 | INFO |   siglip: False\n",
            "2025-04-19,01:43:23 | INFO |   skip_scheduler: False\n",
            "2025-04-19,01:43:23 | INFO |   tensorboard: True\n",
            "2025-04-19,01:43:23 | INFO |   tensorboard_path: ./logs/2025_04_19-01_43_19-model_ViT-B-32-lr_0.001-b_128-j_8-p_amp/tensorboard\n",
            "2025-04-19,01:43:23 | INFO |   torchcompile: False\n",
            "2025-04-19,01:43:23 | INFO |   torchscript: False\n",
            "2025-04-19,01:43:23 | INFO |   trace: False\n",
            "2025-04-19,01:43:23 | INFO |   train_data: 11trainingdata.csv\n",
            "2025-04-19,01:43:23 | INFO |   train_data_upsampling_factors: None\n",
            "2025-04-19,01:43:23 | INFO |   train_num_samples: None\n",
            "2025-04-19,01:43:23 | INFO |   use_bn_sync: False\n",
            "2025-04-19,01:43:23 | INFO |   use_bnb_linear: None\n",
            "2025-04-19,01:43:23 | INFO |   val_data: None\n",
            "2025-04-19,01:43:23 | INFO |   val_frequency: 1\n",
            "2025-04-19,01:43:23 | INFO |   val_num_samples: None\n",
            "2025-04-19,01:43:23 | INFO |   wandb: False\n",
            "2025-04-19,01:43:23 | INFO |   wandb_notes: \n",
            "2025-04-19,01:43:23 | INFO |   wandb_project_name: open-clip\n",
            "2025-04-19,01:43:23 | INFO |   warmup: 10000\n",
            "2025-04-19,01:43:23 | INFO |   wd: 0.1\n",
            "2025-04-19,01:43:23 | INFO |   workers: 8\n",
            "2025-04-19,01:43:23 | INFO |   world_size: 1\n",
            "2025-04-19,01:43:23 | INFO |   zeroshot_frequency: 1\n",
            "2025-04-19,01:43:23 | INFO | Created AdamW (adamw) optimizer: lr: 0.001, betas: (0.9, 0.98), eps: 1e-06, weight_decay: 0.1, amsgrad: False, foreach: None, maximize: False, capturable: False, differentiable: False, fused: None\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "2025-04-19,01:43:23 | INFO | Start epoch 0\n",
            "2025-04-19,01:44:43 | INFO | Train Epoch: 0 [ 128/6707 (2%)] Data (t): 71.541 Batch (t): 80.409, 1.59187/s, 1.59187/s/gpu LR: 0.000000 Logit Scale: 14.286 Contrastive_loss: 4.8546 (4.8546) Loss: 4.8546 (4.8546)\n",
            "2025-04-19,01:51:22 | INFO | Train Epoch: 0 [6656/6707 (100%)] Data (t): 7.216 Batch (t): 7.820, 192.237/s, 192.237/s/gpu LR: 0.000005 Logit Scale: 14.287 Contrastive_loss: 3.2335 (4.0441) Loss: 3.2335 (4.0441)\n",
            "2025-04-19,01:51:32 | INFO | Start epoch 1\n",
            "2025-04-19,01:52:15 | INFO | Train Epoch: 1 [ 128/6707 (2%)] Data (t): 42.100 Batch (t): 43.192, 2.96349/s, 2.96349/s/gpu LR: 0.000005 Logit Scale: 14.288 Contrastive_loss: 3.4077 (3.4077) Loss: 3.4077 (3.4077)\n",
            "2025-04-19,01:55:19 | INFO | Train Epoch: 1 [6656/6707 (100%)] Data (t): 2.826 Batch (t): 3.596, 220.561/s, 220.561/s/gpu LR: 0.000010 Logit Scale: 14.293 Contrastive_loss: 2.6304 (3.0190) Loss: 2.6304 (3.0190)\n",
            "2025-04-19,01:55:30 | INFO | Start epoch 2\n",
            "2025-04-19,01:56:15 | INFO | Train Epoch: 2 [ 128/6707 (2%)] Data (t): 43.801 Batch (t): 44.664, 2.86585/s, 2.86585/s/gpu LR: 0.000010 Logit Scale: 14.293 Contrastive_loss: 2.5928 (2.5928) Loss: 2.5928 (2.5928)\n",
            "2025-04-19,01:59:15 | INFO | Train Epoch: 2 [6656/6707 (100%)] Data (t): 2.760 Batch (t): 3.540, 218.687/s, 218.687/s/gpu LR: 0.000016 Logit Scale: 14.299 Contrastive_loss: 2.3921 (2.4924) Loss: 2.3921 (2.4924)\n",
            "2025-04-19,01:59:35 | INFO | Start epoch 3\n",
            "2025-04-19,02:00:18 | INFO | Train Epoch: 3 [ 128/6707 (2%)] Data (t): 41.580 Batch (t): 42.817, 2.98946/s, 2.98946/s/gpu LR: 0.000016 Logit Scale: 14.299 Contrastive_loss: 2.3220 (2.3220) Loss: 2.3220 (2.3220)\n",
            "2025-04-19,02:03:15 | INFO | Train Epoch: 3 [6656/6707 (100%)] Data (t): 2.669 Batch (t): 3.473, 212.172/s, 212.172/s/gpu LR: 0.000021 Logit Scale: 14.306 Contrastive_loss: 2.1579 (2.2400) Loss: 2.1579 (2.2400)\n",
            "2025-04-19,02:03:37 | INFO | Start epoch 4\n",
            "2025-04-19,02:04:19 | INFO | Train Epoch: 4 [ 128/6707 (2%)] Data (t): 41.471 Batch (t): 42.590, 3.00543/s, 3.00543/s/gpu LR: 0.000021 Logit Scale: 14.306 Contrastive_loss: 2.2149 (2.2149) Loss: 2.2149 (2.2149)\n",
            "2025-04-19,02:07:15 | INFO | Train Epoch: 4 [6656/6707 (100%)] Data (t): 2.605 Batch (t): 3.437, 211.141/s, 211.141/s/gpu LR: 0.000026 Logit Scale: 14.313 Contrastive_loss: 2.2756 (2.2452) Loss: 2.2756 (2.2452)\n",
            "2025-04-19,02:07:27 | INFO | Start epoch 5\n",
            "2025-04-19,02:08:12 | INFO | Train Epoch: 5 [ 128/6707 (2%)] Data (t): 43.541 Batch (t): 44.492, 2.87692/s, 2.87692/s/gpu LR: 0.000026 Logit Scale: 14.313 Contrastive_loss: 2.2674 (2.2674) Loss: 2.2674 (2.2674)\n",
            "2025-04-19,02:11:11 | INFO | Train Epoch: 5 [6656/6707 (100%)] Data (t): 2.725 Batch (t): 3.505, 210.279/s, 210.279/s/gpu LR: 0.000031 Logit Scale: 14.323 Contrastive_loss: 2.2874 (2.2774) Loss: 2.2874 (2.2774)\n",
            "2025-04-19,02:11:27 | INFO | Start epoch 6\n",
            "2025-04-19,02:12:15 | INFO | Train Epoch: 6 [ 128/6707 (2%)] Data (t): 46.545 Batch (t): 47.332, 2.70432/s, 2.70432/s/gpu LR: 0.000031 Logit Scale: 14.323 Contrastive_loss: 2.1926 (2.1926) Loss: 2.1926 (2.1926)\n",
            "2025-04-19,02:15:12 | INFO | Train Epoch: 6 [6656/6707 (100%)] Data (t): 2.701 Batch (t): 3.483, 212.545/s, 212.545/s/gpu LR: 0.000036 Logit Scale: 14.330 Contrastive_loss: 2.2515 (2.2221) Loss: 2.2515 (2.2221)\n",
            "2025-04-19,02:15:33 | INFO | Start epoch 7\n",
            "2025-04-19,02:16:18 | INFO | Train Epoch: 7 [ 128/6707 (2%)] Data (t): 43.774 Batch (t): 44.743, 2.86076/s, 2.86076/s/gpu LR: 0.000036 Logit Scale: 14.330 Contrastive_loss: 2.3563 (2.3563) Loss: 2.3563 (2.3563)\n",
            "2025-04-19,02:19:16 | INFO | Train Epoch: 7 [6656/6707 (100%)] Data (t): 2.726 Batch (t): 3.492, 212.859/s, 212.859/s/gpu LR: 0.000042 Logit Scale: 14.335 Contrastive_loss: 2.2952 (2.3258) Loss: 2.2952 (2.3258)\n",
            "2025-04-19,02:19:42 | INFO | Start epoch 8\n",
            "2025-04-19,02:20:27 | INFO | Train Epoch: 8 [ 128/6707 (2%)] Data (t): 44.000 Batch (t): 44.976, 2.84597/s, 2.84597/s/gpu LR: 0.000042 Logit Scale: 14.335 Contrastive_loss: 2.2173 (2.2173) Loss: 2.2173 (2.2173)\n",
            "2025-04-19,02:23:23 | INFO | Train Epoch: 8 [6656/6707 (100%)] Data (t): 2.682 Batch (t): 3.441, 211.135/s, 211.135/s/gpu LR: 0.000047 Logit Scale: 14.341 Contrastive_loss: 2.3306 (2.2739) Loss: 2.3306 (2.2739)\n",
            "2025-04-19,02:23:33 | INFO | Start epoch 9\n",
            "2025-04-19,02:24:18 | INFO | Train Epoch: 9 [ 128/6707 (2%)] Data (t): 43.209 Batch (t): 44.459, 2.87903/s, 2.87903/s/gpu LR: 0.000047 Logit Scale: 14.342 Contrastive_loss: 2.1792 (2.1792) Loss: 2.1792 (2.1792)\n",
            "2025-04-19,02:27:18 | INFO | Train Epoch: 9 [6656/6707 (100%)] Data (t): 2.770 Batch (t): 3.529, 213.658/s, 213.658/s/gpu LR: 0.000052 Logit Scale: 14.341 Contrastive_loss: 2.2524 (2.2158) Loss: 2.2524 (2.2158)\n",
            "2025-04-19,02:27:44 | INFO | Start epoch 10\n",
            "2025-04-19,02:28:31 | INFO | Train Epoch: 10 [ 128/6707 (2%)] Data (t): 45.110 Batch (t): 46.317, 2.76356/s, 2.76356/s/gpu LR: 0.000052 Logit Scale: 14.341 Contrastive_loss: 2.1917 (2.1917) Loss: 2.1917 (2.1917)\n",
            "2025-04-19,02:31:27 | INFO | Train Epoch: 10 [6656/6707 (100%)] Data (t): 2.689 Batch (t): 3.448, 209.770/s, 209.770/s/gpu LR: 0.000057 Logit Scale: 14.345 Contrastive_loss: 2.3824 (2.2870) Loss: 2.3824 (2.2870)\n",
            "2025-04-19,02:31:54 | INFO | Start epoch 11\n",
            "2025-04-19,02:32:36 | INFO | Train Epoch: 11 [ 128/6707 (2%)] Data (t): 40.482 Batch (t): 42.052, 3.04382/s, 3.04382/s/gpu LR: 0.000057 Logit Scale: 14.344 Contrastive_loss: 2.1611 (2.1611) Loss: 2.1611 (2.1611)\n",
            "2025-04-19,02:35:35 | INFO | Train Epoch: 11 [6656/6707 (100%)] Data (t): 2.670 Batch (t): 3.503, 214.086/s, 214.086/s/gpu LR: 0.000062 Logit Scale: 14.344 Contrastive_loss: 2.1214 (2.1413) Loss: 2.1214 (2.1413)\n",
            "2025-04-19,02:35:48 | INFO | Start epoch 12\n",
            "2025-04-19,02:36:31 | INFO | Train Epoch: 12 [ 128/6707 (2%)] Data (t): 42.149 Batch (t): 43.217, 2.96177/s, 2.96177/s/gpu LR: 0.000063 Logit Scale: 14.344 Contrastive_loss: 2.1580 (2.1580) Loss: 2.1580 (2.1580)\n",
            "2025-04-19,02:39:26 | INFO | Train Epoch: 12 [6656/6707 (100%)] Data (t): 2.667 Batch (t): 3.437, 209.471/s, 209.471/s/gpu LR: 0.000068 Logit Scale: 14.345 Contrastive_loss: 2.3843 (2.2711) Loss: 2.3843 (2.2711)\n",
            "2025-04-19,02:39:46 | INFO | Start epoch 13\n",
            "2025-04-19,02:40:30 | INFO | Train Epoch: 13 [ 128/6707 (2%)] Data (t): 43.061 Batch (t): 44.045, 2.90609/s, 2.90609/s/gpu LR: 0.000068 Logit Scale: 14.344 Contrastive_loss: 2.1963 (2.1963) Loss: 2.1963 (2.1963)\n",
            "2025-04-19,02:43:28 | INFO | Train Epoch: 13 [6656/6707 (100%)] Data (t): 2.733 Batch (t): 3.498, 213.836/s, 213.836/s/gpu LR: 0.000073 Logit Scale: 14.337 Contrastive_loss: 2.5028 (2.3496) Loss: 2.5028 (2.3496)\n",
            "2025-04-19,02:43:45 | INFO | Start epoch 14\n",
            "2025-04-19,02:44:29 | INFO | Train Epoch: 14 [ 128/6707 (2%)] Data (t): 42.449 Batch (t): 43.327, 2.95428/s, 2.95428/s/gpu LR: 0.000073 Logit Scale: 14.336 Contrastive_loss: 2.0622 (2.0622) Loss: 2.0622 (2.0622)\n",
            "2025-04-19,02:47:25 | INFO | Train Epoch: 14 [6656/6707 (100%)] Data (t): 2.644 Batch (t): 3.464, 211.780/s, 211.780/s/gpu LR: 0.000078 Logit Scale: 14.331 Contrastive_loss: 2.1382 (2.1002) Loss: 2.1382 (2.1002)\n",
            "2025-04-19,02:47:49 | INFO | Start epoch 15\n",
            "2025-04-19,02:48:31 | INFO | Train Epoch: 15 [ 128/6707 (2%)] Data (t): 41.436 Batch (t): 42.282, 3.02726/s, 3.02726/s/gpu LR: 0.000078 Logit Scale: 14.331 Contrastive_loss: 2.0297 (2.0297) Loss: 2.0297 (2.0297)\n",
            "2025-04-19,02:51:25 | INFO | Train Epoch: 15 [6656/6707 (100%)] Data (t): 2.625 Batch (t): 3.409, 211.710/s, 211.710/s/gpu LR: 0.000083 Logit Scale: 14.329 Contrastive_loss: 2.2138 (2.1218) Loss: 2.2138 (2.1218)\n",
            "2025-04-19,02:51:38 | INFO | Start epoch 16\n",
            "2025-04-19,02:52:20 | INFO | Train Epoch: 16 [ 128/6707 (2%)] Data (t): 41.006 Batch (t): 42.166, 3.03559/s, 3.03559/s/gpu LR: 0.000083 Logit Scale: 14.329 Contrastive_loss: 2.2314 (2.2314) Loss: 2.2314 (2.2314)\n",
            "2025-04-19,02:55:21 | INFO | Train Epoch: 16 [6656/6707 (100%)] Data (t): 2.694 Batch (t): 3.532, 211.725/s, 211.725/s/gpu LR: 0.000088 Logit Scale: 14.329 Contrastive_loss: 2.0383 (2.1349) Loss: 2.0383 (2.1349)\n",
            "2025-04-19,02:55:42 | INFO | Start epoch 17\n",
            "2025-04-19,02:56:25 | INFO | Train Epoch: 17 [ 128/6707 (2%)] Data (t): 41.751 Batch (t): 43.115, 2.96884/s, 2.96884/s/gpu LR: 0.000088 Logit Scale: 14.329 Contrastive_loss: 2.0339 (2.0339) Loss: 2.0339 (2.0339)\n",
            "2025-04-19,02:59:23 | INFO | Train Epoch: 17 [6656/6707 (100%)] Data (t): 2.670 Batch (t): 3.485, 210.841/s, 210.841/s/gpu LR: 0.000094 Logit Scale: 14.314 Contrastive_loss: 2.1879 (2.1109) Loss: 2.1879 (2.1109)\n",
            "2025-04-19,02:59:42 | INFO | Start epoch 18\n",
            "2025-04-19,03:00:24 | INFO | Train Epoch: 18 [ 128/6707 (2%)] Data (t): 40.726 Batch (t): 41.580, 3.07840/s, 3.07840/s/gpu LR: 0.000094 Logit Scale: 14.313 Contrastive_loss: 2.1272 (2.1272) Loss: 2.1272 (2.1272)\n",
            "2025-04-19,03:03:25 | INFO | Train Epoch: 18 [6656/6707 (100%)] Data (t): 2.725 Batch (t): 3.541, 212.186/s, 212.186/s/gpu LR: 0.000099 Logit Scale: 14.308 Contrastive_loss: 2.2294 (2.1783) Loss: 2.2294 (2.1783)\n",
            "2025-04-19,03:03:45 | INFO | Start epoch 19\n",
            "2025-04-19,03:04:29 | INFO | Train Epoch: 19 [ 128/6707 (2%)] Data (t): 41.878 Batch (t): 43.476, 2.94418/s, 2.94418/s/gpu LR: 0.000099 Logit Scale: 14.307 Contrastive_loss: 2.1071 (2.1071) Loss: 2.1071 (2.1071)\n",
            "2025-04-19,03:07:26 | INFO | Train Epoch: 19 [6656/6707 (100%)] Data (t): 2.686 Batch (t): 3.472, 212.723/s, 212.723/s/gpu LR: 0.000104 Logit Scale: 14.300 Contrastive_loss: 2.2388 (2.1730) Loss: 2.2388 (2.1730)\n",
            "2025-04-19,03:07:51 | INFO | Start epoch 20\n",
            "2025-04-19,03:08:33 | INFO | Train Epoch: 20 [ 128/6707 (2%)] Data (t): 40.236 Batch (t): 41.790, 3.06297/s, 3.06297/s/gpu LR: 0.000104 Logit Scale: 14.300 Contrastive_loss: 2.1056 (2.1056) Loss: 2.1056 (2.1056)\n",
            "2025-04-19,03:11:32 | INFO | Train Epoch: 20 [6656/6707 (100%)] Data (t): 2.729 Batch (t): 3.507, 210.057/s, 210.057/s/gpu LR: 0.000109 Logit Scale: 14.304 Contrastive_loss: 2.1814 (2.1435) Loss: 2.1814 (2.1435)\n",
            "2025-04-19,03:12:22 | INFO | Start epoch 21\n",
            "2025-04-19,03:13:04 | INFO | Train Epoch: 21 [ 128/6707 (2%)] Data (t): 41.267 Batch (t): 42.203, 3.03294/s, 3.03294/s/gpu LR: 0.000109 Logit Scale: 14.304 Contrastive_loss: 2.2981 (2.2981) Loss: 2.2981 (2.2981)\n",
            "2025-04-19,03:16:00 | INFO | Train Epoch: 21 [6656/6707 (100%)] Data (t): 2.647 Batch (t): 3.454, 215.812/s, 215.812/s/gpu LR: 0.000114 Logit Scale: 14.295 Contrastive_loss: 2.1175 (2.2078) Loss: 2.1175 (2.2078)\n",
            "2025-04-19,03:16:50 | INFO | Start epoch 22\n",
            "2025-04-19,03:17:33 | INFO | Train Epoch: 22 [ 128/6707 (2%)] Data (t): 42.391 Batch (t): 43.312, 2.95532/s, 2.95532/s/gpu LR: 0.000115 Logit Scale: 14.295 Contrastive_loss: 2.2446 (2.2446) Loss: 2.2446 (2.2446)\n",
            "2025-04-19,03:20:30 | INFO | Train Epoch: 22 [6656/6707 (100%)] Data (t): 2.698 Batch (t): 3.468, 213.582/s, 213.582/s/gpu LR: 0.000120 Logit Scale: 14.282 Contrastive_loss: 2.1601 (2.2024) Loss: 2.1601 (2.2024)\n",
            "2025-04-19,03:20:50 | INFO | Start epoch 23\n",
            "2025-04-19,03:21:32 | INFO | Train Epoch: 23 [ 128/6707 (2%)] Data (t): 40.764 Batch (t): 41.642, 3.07381/s, 3.07381/s/gpu LR: 0.000120 Logit Scale: 14.283 Contrastive_loss: 2.2475 (2.2475) Loss: 2.2475 (2.2475)\n",
            "2025-04-19,03:24:29 | INFO | Train Epoch: 23 [6656/6707 (100%)] Data (t): 2.702 Batch (t): 3.489, 209.415/s, 209.415/s/gpu LR: 0.000125 Logit Scale: 14.279 Contrastive_loss: 2.2586 (2.2531) Loss: 2.2586 (2.2531)\n",
            "2025-04-19,03:24:55 | INFO | Start epoch 24\n",
            "2025-04-19,03:25:41 | INFO | Train Epoch: 24 [ 128/6707 (2%)] Data (t): 45.125 Batch (t): 46.173, 2.77221/s, 2.77221/s/gpu LR: 0.000125 Logit Scale: 14.278 Contrastive_loss: 2.0910 (2.0910) Loss: 2.0910 (2.0910)\n",
            "2025-04-19,03:28:38 | INFO | Train Epoch: 24 [6656/6707 (100%)] Data (t): 2.679 Batch (t): 3.465, 211.474/s, 211.474/s/gpu LR: 0.000130 Logit Scale: 14.275 Contrastive_loss: 2.1683 (2.1297) Loss: 2.1683 (2.1297)\n",
            "2025-04-19,03:29:06 | INFO | Start epoch 25\n",
            "2025-04-19,03:29:50 | INFO | Train Epoch: 25 [ 128/6707 (2%)] Data (t): 42.492 Batch (t): 44.006, 2.90868/s, 2.90868/s/gpu LR: 0.000130 Logit Scale: 14.275 Contrastive_loss: 2.2473 (2.2473) Loss: 2.2473 (2.2473)\n",
            "2025-04-19,03:32:50 | INFO | Train Epoch: 25 [6656/6707 (100%)] Data (t): 2.743 Batch (t): 3.540, 212.654/s, 212.654/s/gpu LR: 0.000135 Logit Scale: 14.260 Contrastive_loss: 2.0908 (2.1691) Loss: 2.0908 (2.1691)\n",
            "2025-04-19,03:33:11 | INFO | Start epoch 26\n",
            "2025-04-19,03:33:52 | INFO | Train Epoch: 26 [ 128/6707 (2%)] Data (t): 39.224 Batch (t): 40.361, 3.17139/s, 3.17139/s/gpu LR: 0.000135 Logit Scale: 14.260 Contrastive_loss: 2.1834 (2.1834) Loss: 2.1834 (2.1834)\n",
            "2025-04-19,03:36:50 | INFO | Train Epoch: 26 [6656/6707 (100%)] Data (t): 2.708 Batch (t): 3.498, 214.331/s, 214.331/s/gpu LR: 0.000140 Logit Scale: 14.251 Contrastive_loss: 2.1258 (2.1546) Loss: 2.1258 (2.1546)\n",
            "2025-04-19,03:37:20 | INFO | Start epoch 27\n",
            "2025-04-19,03:38:04 | INFO | Train Epoch: 27 [ 128/6707 (2%)] Data (t): 42.845 Batch (t): 44.042, 2.90630/s, 2.90630/s/gpu LR: 0.000140 Logit Scale: 14.251 Contrastive_loss: 2.1458 (2.1458) Loss: 2.1458 (2.1458)\n",
            "2025-04-19,03:41:04 | INFO | Train Epoch: 27 [6656/6707 (100%)] Data (t): 2.739 Batch (t): 3.518, 212.700/s, 212.700/s/gpu LR: 0.000146 Logit Scale: 14.251 Contrastive_loss: 2.2646 (2.2052) Loss: 2.2646 (2.2052)\n",
            "2025-04-19,03:41:31 | INFO | Start epoch 28\n",
            "2025-04-19,03:42:15 | INFO | Train Epoch: 28 [ 128/6707 (2%)] Data (t): 43.473 Batch (t): 44.239, 2.89339/s, 2.89339/s/gpu LR: 0.000146 Logit Scale: 14.250 Contrastive_loss: 2.0772 (2.0772) Loss: 2.0772 (2.0772)\n",
            "2025-04-19,03:45:17 | INFO | Train Epoch: 28 [6656/6707 (100%)] Data (t): 2.757 Batch (t): 3.573, 211.304/s, 211.304/s/gpu LR: 0.000151 Logit Scale: 14.234 Contrastive_loss: 2.1330 (2.1051) Loss: 2.1330 (2.1051)\n",
            "2025-04-19,03:45:33 | INFO | Start epoch 29\n",
            "2025-04-19,03:46:14 | INFO | Train Epoch: 29 [ 128/6707 (2%)] Data (t): 40.780 Batch (t): 41.745, 3.06621/s, 3.06621/s/gpu LR: 0.000151 Logit Scale: 14.233 Contrastive_loss: 2.2165 (2.2165) Loss: 2.2165 (2.2165)\n",
            "2025-04-19,03:49:10 | INFO | Train Epoch: 29 [6656/6707 (100%)] Data (t): 2.639 Batch (t): 3.447, 165.075/s, 165.075/s/gpu LR: 0.000156 Logit Scale: 14.217 Contrastive_loss: 2.1077 (2.1621) Loss: 2.1077 (2.1621)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yZuJoz7WQYum"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}